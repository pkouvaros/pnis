Advances in interconnectivity of autonomous services and machine learning fuel
the development of MAS with arbitrarily many neural-symbolic components,
thereby creating a pressing need for their verification. Towards addressing
this need, in this paper we put forward a number of automated procedures for
the formal analysis of parameterised, neural-symbolic MAS. The procedures
enable conclusions to be drawn on the satisfaction of temporal properties
irrespective of the number of agents composing the MAS and can identify
emergence thresholds expressing the sufficient conditions on the number agents
for a property to be realised. The theoretical results are driven by the
implementation of a parameterised, neural-symbolic verifier, which we used to
reason about a social dilemma game. In future work we will target the
development of parameterised methods for interleaved semantics and strategic properties.


Given the existential nature of some challenges which come in the form of CRDs,
such as the collective maintenance of Earth's habitat by humanity
\cite{Smirnov19}, we as a species cannot remain unprepared to reliably avoid
their worst outcomes. The solution to the verification and
emergence identification problems presented here
provides a framework for creating autonomous agents which can avoid mutual
defection in CRDs, as well as for analysing models of natural systems which
already do.

One example of this might be the huddling of emperor penguins to conserve
energy and incubate eggs \cite{GilbertRLNA06} during the
% The Emperor Penguin, Le Maho, 1977 
arctic winter, the success of which depends on a slow rotation of members of
the formation away from the chilling wind \cite{WatersBK12}.
