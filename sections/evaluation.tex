
In this section we present an evaluation of the parameterised verification
procedure described in Section~\ref{sec:verification} for the guarding game
presented in Example~\ref{ex:agent-template}.


%%%%
The guarding game is an instance of a social dilemma game, a class of
MASs characterised by tension between individual
and collective rationality \cite{VanlangeJPV13}. The guarding game simulates
the fundamental forces of a \emph{collective risk dilemma (CRD)}, a type of
social dilemma where a guaranteed ``tragedy of the commons''
\cite{Hardin68} is avoided by personal sacrifice by a population of
agents, or brought on by free riding if all the agents favour a strategy which
neglects the collective interests of that personal sacrifice \cite{SantosP11}.
%
Namely, guarding can be considered equivalent to cooperation (acting in
collective interest), and resting to defection (acting in selfish
interest).


To train a neural observation function, we used deep Q-learning, a type of
reinforcement learning (RL) algorithm. During the training, the game was played
by 3 agents, and the parameters were set as $M_h = 4$, $G_r = -2$, $R_r = 1$
and $U_r = -3$. The rewards were assigned to reflect the tension between
individual and collective interests. All agents shared the same neural network,
creating a system in which the agents were learning to play against exact
copies of themselves. We used an experience replay buffer and a separate target
network which was updated only periodically to stabilise overestimation of the
Q-values \cite{Mnih+15,HaaseltGS16}. More details about the training can be
found in the appendix.
%
The produced neural network has two hidden layers of four ReLU activated
neurons, takes as input a single neuron, representing the normalised health
points of the agent, and outputs the estimated Q-values of the two actions
`rest' and `guard'.
%%%%


\begin{table}
\centering
\begin{tabular}{c@{\qquad}rrrrr}
  \toprule
  k &\multicolumn{1}{c}{$n=2$} & \multicolumn{1}{c}{$n=3$} & \multicolumn{1}{c}{$n=4$} & \multicolumn{1}{c}{$n=5$} & \multicolumn{1}{c}{$n=6$}\\\midrule
  
  2 &              0.09s &     0.13s &   0.53s &    1.15s &              5.09s\\
  3 & \graycell    1.46s &     0.30s &   1.19s &    3.41s &             17.58s\\
  4 & \graycell    5.49s &     0.52s &   2.31s &   17.74s & \multicolumn{1}{c}{--}\\
  5 & \graycell   61.47s &   133.28s &   4.28s &   95.83s & \multicolumn{1}{c}{--}\\
  \bottomrule
\end{tabular}
\caption{ Verification times for $\msys n \models \varphi^k_E[m]$ for $m=2$ and
  various $k$ and $n$.  Grey cells indicate when the property was not
  satisfied.  Dashes indicate a 1 hour timeout.  }
  \label{tab:results-existential}
\end{table}

Given the learned neural network, we implemented a template agent and a
zero-one agent for the guarding game. We then used the \venmas toolkit
developed for verification of NISs~\cite{Akintunde+20b} to verify whether it is
possible for a colony of agents to survive after a number of time steps.
%
Specifically, recall from Example~\ref{ex:pnis} the proposition $\mathsf{a}$
that labels all states with positive health (``alive'') and the proposition
$\mathsf{d}$ that labels all other states (``dead'').
%
Let $m$ be the number of agent variables. We are interested in verifying two
specifications (for $v_i \in\atvar$):
\begin{inparaenum}[\it (i)]
\item existential property
  $\varphi^k_E = EX^k \bigwedge_{i=1}^m(\mathsf{a},v_i)$ 
  expressing there is an evolution where at least $m$ agents are alive after
  $k$ time steps,
\item universal property $\varphi^k_A = AX^k \bigwedge_{i=1}^m(\mathsf{a},v_i)$
  expressing that in every possible evolution at least $m$ agents are alive
  after $k$ time steps.
\end{inparaenum}
%
The experiments have been performed on a standard PC running Ubuntu 22.04 with
16GB RAM and processor Intel(R) Core i5-4460 CPU @ 3.20GHz. We relied on Gurobi
v10.0 to solve MILP \cite{Gurobi+16a}.

For the existential property, we consider the case of $m=2$ and are interested
in finding the minimal number of agents in the colony that is required to
guarantee that at least two agents can stay alive for a given number of
steps. We vary the temporal depth $k$ of the property, from 2 till 6, and the
total number $n$ of agents from 2 to 6, and verify the property against
concrete NISs $\sys{n}$ composed of $n$ concrete agents.  The outcomes of the
verification queries are presented in Table~\ref{tab:results-existential}.
%
For temporal depth $k=2$, we have that
$\pnis\models \forall_{v_1,v_2}\varphi^k_E$. However, for $k\geq 3$,
$\pnis\not\models\forall_{v_1,v_2}\varphi^k_E$ as a system composed of two
agents only does not satisfy it, i.e.,
$\msys{2}\not\models\forall_{v_1,v_2}\varphi^k_E$. On the other hand, $n=3$ is
the emergence threshold for $\forall_{v_1,v_2}\varphi^k_E$ when $k\geq 3$. This
result is what we would expect from a cooperative template agent for the given
parameters of the guarding game. We can therefore conclude that the RL
procedure has been adequate for training altruistic agents.

The arbitrary selection of a subset of guards that volunteer is a
necessary artefact of the interpreted systems, but does not affect the
stability of the system negatively and allows us to reason about its
existential properties, as the only event which would incur the tragedy of the
commons is the lack of any volunteer guards in the first place.


For the universal property, we verified $\varphi^k_A[m]$ against $\masys{m}$
for temporal depth $k = 1,\dots,6$ and the number of agents $m=2,3$. The
verification results can be found in Table~\ref{tab:results-universal}.  When
we could get the result within the timeout, none of the properties has been
satisfied. This is a consequence of the semantics of our PNIS, where even when
the agents volunteer to guard, they can choose either to rest or to guard, and
so there is a path in the model where nobody is guarding and a path where
everybody is guarding, thus everyone's health deteriorates. This result
highlights the need for some arbitration in the social dilemma settings that
would follow some reasonable strategy instead of letting the system evolve due
to a chance.

\begin{table}
  \centering
  \begin{tabular}{@{}crrrrrr@{}}
    \toprule
    % $k$ & \multicolumn{1}{c}{$m = 2$} & \multicolumn{1}{c}{$m = 3$}\\
    % \midrule
    % 1 & \graycell        0.66s      & \graycell        1.75s\\
    % 2 & \graycell        3.60s      & \graycell       16.03s\\
    % 3 & \multicolumn{1}{c}{--}      & \graycell        0.00s\\
    % 4 & \graycell       16.90s      & \multicolumn{1}{c}{--}\\
    % 5 & \graycell       20.59s      & \multicolumn{1}{c}{--}\\
    % 6 & \multicolumn{1}{c}{--}      & \multicolumn{1}{c}{--}\\

    m & \multicolumn{1}{c}{$k = 1$} & \multicolumn{1}{c}{$k = 2$} & \multicolumn{1}{c}{$k = 3$} & \multicolumn{1}{c}{$k = 4$} & \multicolumn{1}{c}{$k = 5$} & \multicolumn{1}{c}{$k = 6$}\\
    \midrule
2 & \graycell    0.66s & \graycell    3.60s & \multicolumn{1}{c}{--} & \graycell   16.90s & \graycell   20.59s & \multicolumn{1}{c}{--}\\
3 & \graycell    1.75s & \graycell   16.03s & \multicolumn{1}{c}{--} & \graycell 42.74s & \graycell 2196.70s & \multicolumn{1}{c}{--} \\
    \bottomrule
  \end{tabular}
  \caption{ Verification times for $\masys{m} \models \varphi^k_A[m]$ for various
    $m$ and $k$.  Grey cells indicate when the property was not satisfied.
    Dashes indicate a 1 hour timeout.  }
  \label{tab:results-universal}
\end{table}



%%% Local Variables:
%%% mode: latex
%%% fill-column: 79
%%% TeX-master: "../main"
%%% End:
